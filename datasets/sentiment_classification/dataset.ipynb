{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "POSITIVE    657\n",
       "NEGATIVE    362\n",
       "NEUTRAL     280\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "1    657\n",
       "0    362\n",
       "2    280\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# データの読み込み\n",
    "filepath = '../origin/categorize.csv'\n",
    "df = pd.read_csv(filepath)[['mail', 'sentiment']]\n",
    "display(df['sentiment'].value_counts())\n",
    "\n",
    "# ニュートラルを除外\n",
    "# df = df[df['sentiment'] != 'NEUTRAL']\n",
    "\n",
    "# ラベルを数値に変換\n",
    "label_map = { 'NEGATIVE': 0, 'POSITIVE': 1, 'NEUTRAL': 2}\n",
    "df['sentiment'] = df['sentiment'].map(label_map)\n",
    "display(df['sentiment'].value_counts())\n",
    "\n",
    "df.rename(columns={'mail':'text', 'sentiment':'label'}, inplace=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], df['label'], train_size=0.5, random_state=42, stratify=df['label'])\n",
    "\n",
    "X_test, X_eval, y_test, y_eval = train_test_split(\n",
    "    X_test, y_test, train_size=0.5, random_state=42, stratify=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame({'text': X_train, 'label': y_train})\n",
    "test_df = pd.DataFrame({'text': X_test, 'label': y_test})\n",
    "eval_df = pd.DataFrame({'text': X_eval, 'label': y_eval})\n",
    "test_df.drop(index=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((649, 2), (324, 2), (325, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape, eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('./train.csv', index=False, header=False)\n",
    "test_df.to_csv('./test.csv', index=False, header=False)\n",
    "eval_df.to_csv('./eval.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/datasets/create_dataset\n",
    "from datasets import DatasetBuilder, GeneratorBasedBuilder\n",
    "import datasets\n",
    "import csv\n",
    "\n",
    "class FTDataset(GeneratorBasedBuilder):\n",
    "    def _info(self):\n",
    "        return datasets.DatasetInfo(\n",
    "            features=datasets.Features({\n",
    "                'text': datasets.Value('string'),\n",
    "                'label': datasets.ClassLabel(names=['negative', 'positive', 'neutral']),\n",
    "            }),\n",
    "        )\n",
    "    def _split_generators(self, dl_manager):\n",
    "        \"\"\"Returns SplitGenerators.\"\"\"\n",
    "\n",
    "        train_path = './train.csv'\n",
    "        test_path = './test.csv'\n",
    "        eval_path = './eval.csv'\n",
    "\n",
    "        return [\n",
    "            datasets.SplitGenerator(name=datasets.Split.TRAIN, gen_kwargs={\"filepath\": train_path}),\n",
    "            datasets.SplitGenerator(name=datasets.Split.TEST, gen_kwargs={\"filepath\": test_path}),\n",
    "            datasets.SplitGenerator(name=datasets.Split.VALIDATION, gen_kwargs={\"filepath\": eval_path}),\n",
    "        ]\n",
    "\n",
    "    def _generate_examples(self, filepath):\n",
    "        # CSVファイルを行ごとに読み込み、それぞれの行をHugging Faceデータセットの形式に変換\n",
    "        with open(filepath, encoding='utf-8') as csv_file:\n",
    "            csv_reader = csv.reader(csv_file)\n",
    "            for id_, row in enumerate(csv_reader):\n",
    "                yield id_, {\n",
    "                    'text': row[0], \n",
    "                    'label': row[1], \n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 649\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 324\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 325\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('dataset_loader.py', name='sentiment_dataset')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

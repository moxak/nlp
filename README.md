# NLP

## 環境構築

Poetryを使用します。

1. Poetryのインストール
```bash
# Windows
(Invoke-WebRequest -Uri https://install.python-poetry.org -UseBasicParsing).Content | py -
# Mac
curl -sSL https://install.python-poetry.org | python -
echo 'export PATH="/Users/satoru/.local/bin:$PATH"' >> ~/.zshrc
source ~/.zshrc
```
2. 設定を変更する

```bash
poetry config --list
poetry config virtualenvs.in-project true # プロジェクトフォルダ内に.venvディレクトリを作成する
```
3. Python & ライブラリインストール

```bash
poetry install
```

## ファインチューニング検証

### 目的

- GPTが担っていたタスクの一部を別の言語モデルに切り出すことで、処理の高速化(小規模のモデルの方が結果を返すまでの時間が短い)・API利用料の削減を実現したい
- GPTの入力と出力の対を学習データとして小規模言語モデルをファインチューニングする(知識蒸留)ことで、GPTと遜色のない出力ができるようにモデルを訓練できるかを検証する
- 評価方法はタスク依存だが、基本はGPTとどの程度出力が近いか？を判断基準とする。現状GPTにやらせているタスク自体、どのように評価するかが曖昧なため応急処置的な評価方法である点に注意。

### 手順

1. タスクの設定

2. タスク学習用・評価用のデータセットを準備

    - 学習用：(GPTを使い)自動で作成
    - 評価用：手動or半手動で作成

    - 必要データ量

3. ファインチューニング: `fine-tuning.ipynb`

4. 評価の実施: `evaluation.ipynb`



|タスク|学習データ|評価データ|結果||
|---|---|---|---|---|
|感情分析||||`sentiment_classification`|
|固有名詞判定(固有表現抽出)||||`proper_noun_detection`|
|人名マスキング||||-|
|商品タグ付け||||-|
|サービス・店舗タグ付け||||-|

### モデル選択

- [日本語言語理解ベンチマークJGLUEの構築 〜 自然言語処理モデルの評価用データセットを公開しました](https://techblog.yahoo.co.jp/entry/2022122030379907/)

### ファインチューニング方法

- [huggingfaceのTrainerクラスを使えばFineTuningの学習コードがスッキリ書けてめちゃくちゃ便利です](https://qiita.com/m__k/items/2c4e476d7ac81a3a44af)
- [Hugging Face謹製のTrainerが結構便利というお話](https://qiita.com/tealgreen0503/items/246b7e15e2962b6f9c2b)

### 課題

- 損失関数が愚直すぎる
  - 例えばPositiveラベルのものをNeutralと予測したのと、Negativeと予測したもので等しい損失として計上されている。Negativeと間違えたものの損失を重くするべきでは
  
- モデルのハイパーパラメーター探索が十分でない
  - Baseモデル＞Largeモデルという精度結果になっている背景には、ハイパーパラメーターの設定が適切ではないという要因があると思っている。
  - LargeモデルをFTしたモデルではほぼすべてのラベルを1と予測してしまう過学習状態になることを確認している。learning_rateやweight_decay, optimizerの変更の検討すべきだ。

- [感情分析にはどのような課題がありますか? - AWS/機械学習/機械学習とAI/感情分析とは何ですか?](https://aws.amazon.com/jp/what-is/sentiment-analysis/#seo-faq-pairs#challenges-sa)
    - 皮肉
        - 皮肉を構成する文の感情をコンピュータで分析することは非常に困難です。次の文を考えてみましょう。「確かにすばらしいことです。私の注文が届くまでに 3 週間かかりました」。コンピュータがシナリオを完全に理解して文を分析しない限り、この体験は、「すばらしい」という言葉に基づいて肯定的とラベル付けされることになります。

    - 否定
        - 否定とは、文の反転した意味を伝えるために否定的な言葉を使用することです。例えば、「私はサブスクリプションが高額であったとは言いません」について考えてみましょう。 感情分析アルゴリズムでは、このような文を正しく解釈するのが難しい場合があります。特に、「私はサブスクリプションが安価であると思いました。そうではありませんでした」のように、2 つの文にまたがって否定が生じる場合は困難です。

    - 多極性
        - 多極性は、文に複数の感情が含まれている場合に発生します。例えば、「頑丈な造りであることには満足していますが、色には感心していません」という製品レビューがあります。 この文の根底にある感情をソフトウェアが解釈するのは困難です。各エンティティとそれに対応する感情を抽出するには、アスペクトベースの感情分析を使用する必要があります。 
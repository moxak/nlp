{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2tag = pd.read_csv('data/カテゴリー・タグ定義.csv', encoding='cp932')['タグ'].to_dict()\n",
    "tag2id = {v:k for k, v in id2tag.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag\n",
       "接客態度           319\n",
       "レジ処理の速度        132\n",
       "デイリー           123\n",
       "商品在庫            62\n",
       "店内レイアウト         56\n",
       "商品陳列            51\n",
       "商品知識            37\n",
       "割引サービス          29\n",
       "フード＆ドリンク        23\n",
       "ホームグッズ          23\n",
       "駐車場             23\n",
       "店内の清潔度          21\n",
       "デイリーグッズ         17\n",
       "ヘルスケア           17\n",
       "欠品              15\n",
       "商品価格            15\n",
       "ベジタブル・フルーツ      11\n",
       "ペット＆ガーデン         9\n",
       "ファッション＆カバン       7\n",
       "トイレ設備            7\n",
       "デリカ              7\n",
       "その他サービス          7\n",
       "リカー＆ワイン          7\n",
       "菓子・珍味            6\n",
       "ホームエレクトロニクス      5\n",
       "サイクル             5\n",
       "トイ＆バラエティ         5\n",
       "その他設備            4\n",
       "ハンディキャップ対応       4\n",
       "安全対策             3\n",
       "カーライフ            3\n",
       "スマホパーツ           3\n",
       "ホームインテリア         3\n",
       "音響設備             2\n",
       "フレッシュミート         2\n",
       "スキンケア            2\n",
       "ブランドファッション       1\n",
       "メンズインナー          1\n",
       "理美容家電            1\n",
       "空調               1\n",
       "照明設備             1\n",
       "シューズ             1\n",
       "寝具               1\n",
       "コスメ              1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tag\n",
       "40    319\n",
       "41    132\n",
       "30    123\n",
       "45     62\n",
       "43     56\n",
       "44     51\n",
       "39     37\n",
       "46     29\n",
       "29     23\n",
       "8      23\n",
       "52     23\n",
       "42     21\n",
       "15     17\n",
       "16     17\n",
       "48     15\n",
       "38     15\n",
       "36     11\n",
       "17      9\n",
       "19      7\n",
       "55      7\n",
       "34      7\n",
       "49      7\n",
       "31      7\n",
       "33      6\n",
       "2       5\n",
       "10      5\n",
       "1       5\n",
       "57      4\n",
       "56      4\n",
       "54      3\n",
       "0       3\n",
       "3       3\n",
       "7       3\n",
       "51      2\n",
       "35      2\n",
       "28      2\n",
       "20      1\n",
       "18      1\n",
       "6       1\n",
       "53      1\n",
       "50      1\n",
       "22      1\n",
       "11      1\n",
       "25      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# データの読み込み\n",
    "filepath = \"data/20230926_ft.csv\"\n",
    "df = pd.read_csv(filepath)[['comment', 'tag']]\n",
    "display(df['tag'].value_counts())\n",
    "\n",
    "# ニュートラルを除外\n",
    "# df = df[df['sentiment'] != 'NEUTRAL']\n",
    "\n",
    "# ラベルを数値に変換\n",
    "df['tag'] = df['tag'].map(tag2id)\n",
    "display(df['tag'].value_counts())\n",
    "\n",
    "df.rename(columns={'comment':'text', 'tag':'label'}, inplace=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], df['label'], train_size=0.5, random_state=42)\n",
    "\n",
    "X_test, X_eval, y_test, y_eval = train_test_split(\n",
    "    X_test, y_test, train_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame({'text': X_train, 'label': y_train})\n",
    "test_df = pd.DataFrame({'text': X_test, 'label': y_test})\n",
    "eval_df = pd.DataFrame({'text': X_eval, 'label': y_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((536, 2), (268, 2), (269, 2))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape, eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = 'data/fine-tuning'\n",
    "os.makedirs(DATASET_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(f'./{DATASET_DIR}/train.csv', index=False, header=False)\n",
    "test_df.to_csv(f'./{DATASET_DIR}/test.csv', index=False, header=False)\n",
    "eval_df.to_csv(f'./{DATASET_DIR}/eval.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/datasets/create_dataset\n",
    "from datasets import DatasetBuilder, GeneratorBasedBuilder\n",
    "import datasets\n",
    "import csv\n",
    "\n",
    "DATASET_DIR = 'data/fine-tuning'\n",
    "\n",
    "class FTDataset(GeneratorBasedBuilder):\n",
    "    def _info(self):\n",
    "        return datasets.DatasetInfo(\n",
    "            features=datasets.Features({\n",
    "                'text': datasets.Value('string'),\n",
    "                'label': datasets.ClassLabel(names=list(id2tag.values())),\n",
    "            }),\n",
    "        )\n",
    "    def _split_generators(self, dl_manager):\n",
    "        \"\"\"Returns SplitGenerators.\"\"\"\n",
    "\n",
    "        train_path = f'./{DATASET_DIR}/train.csv'\n",
    "        test_path = f'./{DATASET_DIR}/test.csv'\n",
    "        eval_path = f'./{DATASET_DIR}/eval.csv'\n",
    "\n",
    "        return [\n",
    "            datasets.SplitGenerator(name=datasets.Split.TRAIN, gen_kwargs={\"filepath\": train_path}),\n",
    "            datasets.SplitGenerator(name=datasets.Split.TEST, gen_kwargs={\"filepath\": test_path}),\n",
    "            datasets.SplitGenerator(name=datasets.Split.VALIDATION, gen_kwargs={\"filepath\": eval_path}),\n",
    "        ]\n",
    "\n",
    "    def _generate_examples(self, filepath):\n",
    "        # CSVファイルを行ごとに読み込み、それぞれの行をHugging Faceデータセットの形式に変換\n",
    "        with open(filepath, encoding='utf-8') as csv_file:\n",
    "            csv_reader = csv.reader(csv_file)\n",
    "            for id_, row in enumerate(csv_reader):\n",
    "                yield id_, {\n",
    "                    'text': row[0], \n",
    "                    'label': row[1], \n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e68a0e951821455a8c11c031fe809c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413f3f41b1db4119a9c57d2c8b900b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "650e9bddafcd485aadcd3bc671bd4755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 536\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 268\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 269\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('dataset_loader.py', name='category-tagging')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'カーライフ',\n",
       " 1: 'トイ＆バラエティ',\n",
       " 2: 'ホームエレクトロニクス',\n",
       " 3: 'スマホパーツ',\n",
       " 4: 'ラブグッズ',\n",
       " 5: 'パーティーグッズ',\n",
       " 6: '理美容家電',\n",
       " 7: 'ホームインテリア',\n",
       " 8: 'ホームグッズ',\n",
       " 9: 'カーペンター＆ツール',\n",
       " 10: 'サイクル',\n",
       " 11: '寝具',\n",
       " 12: 'プロテイン・トレーニング',\n",
       " 13: 'アウトドア',\n",
       " 14: 'フューチャープロダクト',\n",
       " 15: 'デイリーグッズ',\n",
       " 16: 'ヘルスケア',\n",
       " 17: 'ペット＆ガーデン',\n",
       " 18: 'メンズインナー',\n",
       " 19: 'ファッション＆カバン',\n",
       " 20: 'ブランドファッション',\n",
       " 21: 'インポート',\n",
       " 22: 'シューズ',\n",
       " 23: 'レディス・キッズインナー',\n",
       " 24: 'アロマ',\n",
       " 25: 'コスメ',\n",
       " 26: 'ステーショナリー',\n",
       " 27: 'レディスファッション雑貨',\n",
       " 28: 'スキンケア',\n",
       " 29: 'フード＆ドリンク',\n",
       " 30: 'デイリー',\n",
       " 31: 'リカー＆ワイン',\n",
       " 32: 'ギフト',\n",
       " 33: '菓子・珍味',\n",
       " 34: 'デリカ',\n",
       " 35: 'フレッシュミート',\n",
       " 36: 'ベジタブル・フルーツ',\n",
       " 37: 'フレッシュフィッシュ',\n",
       " 38: '商品価格',\n",
       " 39: '商品知識',\n",
       " 40: '接客態度',\n",
       " 41: 'レジ処理の速度',\n",
       " 42: '店内の清潔度',\n",
       " 43: '店内レイアウト',\n",
       " 44: '商品陳列',\n",
       " 45: '商品在庫',\n",
       " 46: '割引サービス',\n",
       " 47: '会計',\n",
       " 48: '欠品',\n",
       " 49: 'その他サービス',\n",
       " 50: '照明設備',\n",
       " 51: '音響設備',\n",
       " 52: '駐車場',\n",
       " 53: '空調',\n",
       " 54: '安全対策',\n",
       " 55: 'トイレ設備',\n",
       " 56: 'ハンディキャップ対応',\n",
       " 57: 'その他設備'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9422e61643bc341e0075e9a11dbab7b6575580aac996b9891ea3fbf3f8411f43"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
